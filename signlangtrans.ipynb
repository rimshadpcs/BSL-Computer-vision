{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BBWhL847y89"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-2yeVHY01d4",
        "outputId": "f112e5ab-9b12-4107-c639-d3a81aab7f7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9JTRDJ_gGe"
      },
      "source": [
        "train=!unzip /content/drive/MyDrive/projectfiles/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_GoyCxD_gvH"
      },
      "source": [
        "test=!unzip /content/drive/MyDrive/projectfiles/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q9OTJKk98NP"
      },
      "source": [
        " #!pip uninstall protobuf matplotlib -y\n",
        " #!pip install protobuf matplotlib==3.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IXWTVH59DRs"
      },
      "source": [
        "#!pip uninstall tensorflow keras -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6JzT2Pf74R_"
      },
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sArB08fQ787c"
      },
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP98t-gl8GWq"
      },
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cnqL4ZX8Ipm"
      },
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGFnRKoC8K2U",
        "outputId": "a44de10f-0df5-4c18-b6dc-acf8a50ea600"
      },
      "source": [
        "if os.name=='posix':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=b9322f0ff85abfa3e79f2aec449aeb92ff9bb1f769250253cadae5f992525266\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dVhfGjz8N06",
        "outputId": "1cfac80d-3bb8-4d97-ec59-79adebc13bca"
      },
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 60289, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 60289 (delta 19), reused 36 (delta 0), pack-reused 60234\u001b[K\n",
            "Receiving objects: 100% (60289/60289), 573.82 MiB | 37.64 MiB/s, done.\n",
            "Resolving deltas: 100% (41921/41921), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5uvxyUQ0ULd",
        "outputId": "08fea5f2-52c9-4fbe-c156-6add543e769c"
      },
      "source": [
        "# copying training images\n",
        "!cp -r -v train Tensorflow/workspace/images/\n",
        "# copying test images\n",
        "!cp -r -v test Tensorflow/workspace/images/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'train' -> 'Tensorflow/workspace/images/train'\n",
            "'train/yes00509.xml' -> 'Tensorflow/workspace/images/train/yes00509.xml'\n",
            "'train/who00510.xml' -> 'Tensorflow/workspace/images/train/who00510.xml'\n",
            "'train/you00501.xml' -> 'Tensorflow/workspace/images/train/you00501.xml'\n",
            "'train/you00508.xml' -> 'Tensorflow/workspace/images/train/you00508.xml'\n",
            "'train/you00505.xml' -> 'Tensorflow/workspace/images/train/you00505.xml'\n",
            "'train/who00508.xml' -> 'Tensorflow/workspace/images/train/who00508.xml'\n",
            "'train/yes00513.xml' -> 'Tensorflow/workspace/images/train/yes00513.xml'\n",
            "'train/yes00510.xml' -> 'Tensorflow/workspace/images/train/yes00510.xml'\n",
            "'train/you00509.xml' -> 'Tensorflow/workspace/images/train/you00509.xml'\n",
            "'train/yes00501.xml' -> 'Tensorflow/workspace/images/train/yes00501.xml'\n",
            "'train/yes00511.xml' -> 'Tensorflow/workspace/images/train/yes00511.xml'\n",
            "'train/you00506.xml' -> 'Tensorflow/workspace/images/train/you00506.xml'\n",
            "'train/yes00506.xml' -> 'Tensorflow/workspace/images/train/yes00506.xml'\n",
            "'train/you00502.xml' -> 'Tensorflow/workspace/images/train/you00502.xml'\n",
            "'train/who00507.xml' -> 'Tensorflow/workspace/images/train/who00507.xml'\n",
            "'train/yes00508.xml' -> 'Tensorflow/workspace/images/train/yes00508.xml'\n",
            "'train/yes00504.xml' -> 'Tensorflow/workspace/images/train/yes00504.xml'\n",
            "'train/yes00512.xml' -> 'Tensorflow/workspace/images/train/yes00512.xml'\n",
            "'train/yes00505.xml' -> 'Tensorflow/workspace/images/train/yes00505.xml'\n",
            "'train/you00504.xml' -> 'Tensorflow/workspace/images/train/you00504.xml'\n",
            "'train/yes00502.xml' -> 'Tensorflow/workspace/images/train/yes00502.xml'\n",
            "'train/you00503.xml' -> 'Tensorflow/workspace/images/train/you00503.xml'\n",
            "'train/yes00503.xml' -> 'Tensorflow/workspace/images/train/yes00503.xml'\n",
            "'train/you00511.xml' -> 'Tensorflow/workspace/images/train/you00511.xml'\n",
            "'train/who00509.xml' -> 'Tensorflow/workspace/images/train/who00509.xml'\n",
            "'train/which00509.xml' -> 'Tensorflow/workspace/images/train/which00509.xml'\n",
            "'train/where00511.xml' -> 'Tensorflow/workspace/images/train/where00511.xml'\n",
            "'train/who00502.xml' -> 'Tensorflow/workspace/images/train/who00502.xml'\n",
            "'train/which00508.xml' -> 'Tensorflow/workspace/images/train/which00508.xml'\n",
            "'train/where00506.xml' -> 'Tensorflow/workspace/images/train/where00506.xml'\n",
            "'train/where00509.xml' -> 'Tensorflow/workspace/images/train/where00509.xml'\n",
            "'train/who00501.xml' -> 'Tensorflow/workspace/images/train/who00501.xml'\n",
            "'train/where00505.xml' -> 'Tensorflow/workspace/images/train/where00505.xml'\n",
            "'train/where00510.xml' -> 'Tensorflow/workspace/images/train/where00510.xml'\n",
            "'train/where00508.xml' -> 'Tensorflow/workspace/images/train/where00508.xml'\n",
            "'train/which00511.xml' -> 'Tensorflow/workspace/images/train/which00511.xml'\n",
            "'train/which00512.xml' -> 'Tensorflow/workspace/images/train/which00512.xml'\n",
            "'train/who00503.xml' -> 'Tensorflow/workspace/images/train/who00503.xml'\n",
            "'train/which00504.xml' -> 'Tensorflow/workspace/images/train/which00504.xml'\n",
            "'train/where00504.xml' -> 'Tensorflow/workspace/images/train/where00504.xml'\n",
            "'train/which00503.xml' -> 'Tensorflow/workspace/images/train/which00503.xml'\n",
            "'train/who00504.xml' -> 'Tensorflow/workspace/images/train/who00504.xml'\n",
            "'train/where00507.xml' -> 'Tensorflow/workspace/images/train/where00507.xml'\n",
            "'train/who00505.xml' -> 'Tensorflow/workspace/images/train/who00505.xml'\n",
            "'train/where00503.xml' -> 'Tensorflow/workspace/images/train/where00503.xml'\n",
            "'train/which00502.xml' -> 'Tensorflow/workspace/images/train/which00502.xml'\n",
            "'train/which00507.xml' -> 'Tensorflow/workspace/images/train/which00507.xml'\n",
            "'train/which00506.xml' -> 'Tensorflow/workspace/images/train/which00506.xml'\n",
            "'train/which00510.xml' -> 'Tensorflow/workspace/images/train/which00510.xml'\n",
            "'train/which00505.xml' -> 'Tensorflow/workspace/images/train/which00505.xml'\n",
            "'train/welcome00513.xml' -> 'Tensorflow/workspace/images/train/welcome00513.xml'\n",
            "'train/welcome00510.xml' -> 'Tensorflow/workspace/images/train/welcome00510.xml'\n",
            "'train/sorry00508.xml' -> 'Tensorflow/workspace/images/train/sorry00508.xml'\n",
            "'train/what00503.xml' -> 'Tensorflow/workspace/images/train/what00503.xml'\n",
            "'train/welcome00515.xml' -> 'Tensorflow/workspace/images/train/welcome00515.xml'\n",
            "'train/sorry00505.xml' -> 'Tensorflow/workspace/images/train/sorry00505.xml'\n",
            "'train/what00510.xml' -> 'Tensorflow/workspace/images/train/what00510.xml'\n",
            "'train/welcome00512.xml' -> 'Tensorflow/workspace/images/train/welcome00512.xml'\n",
            "'train/welcome00517.xml' -> 'Tensorflow/workspace/images/train/welcome00517.xml'\n",
            "'train/what00502.xml' -> 'Tensorflow/workspace/images/train/what00502.xml'\n",
            "'train/what00501.xml' -> 'Tensorflow/workspace/images/train/what00501.xml'\n",
            "'train/what00507.xml' -> 'Tensorflow/workspace/images/train/what00507.xml'\n",
            "'train/welcome00514.xml' -> 'Tensorflow/workspace/images/train/welcome00514.xml'\n",
            "'train/what00505.xml' -> 'Tensorflow/workspace/images/train/what00505.xml'\n",
            "'train/sorry00507.xml' -> 'Tensorflow/workspace/images/train/sorry00507.xml'\n",
            "'train/where00502.xml' -> 'Tensorflow/workspace/images/train/where00502.xml'\n",
            "'train/what00508.xml' -> 'Tensorflow/workspace/images/train/what00508.xml'\n",
            "'train/what00506.xml' -> 'Tensorflow/workspace/images/train/what00506.xml'\n",
            "'train/sorry00506.xml' -> 'Tensorflow/workspace/images/train/sorry00506.xml'\n",
            "'train/welcome00511.xml' -> 'Tensorflow/workspace/images/train/welcome00511.xml'\n",
            "'train/sorry00511.xml' -> 'Tensorflow/workspace/images/train/sorry00511.xml'\n",
            "'train/sorry00509.xml' -> 'Tensorflow/workspace/images/train/sorry00509.xml'\n",
            "'train/welcome00516.xml' -> 'Tensorflow/workspace/images/train/welcome00516.xml'\n",
            "'train/what00509.xml' -> 'Tensorflow/workspace/images/train/what00509.xml'\n",
            "'train/welcome00518.xml' -> 'Tensorflow/workspace/images/train/welcome00518.xml'\n",
            "'train/sorry00501.xml' -> 'Tensorflow/workspace/images/train/sorry00501.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #4.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #4.xml'\n",
            "'train/please00503.xml' -> 'Tensorflow/workspace/images/train/please00503.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #7.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #7.xml'\n",
            "'train/please00505.xml' -> 'Tensorflow/workspace/images/train/please00505.xml'\n",
            "'train/please00507.xml' -> 'Tensorflow/workspace/images/train/please00507.xml'\n",
            "'train/please00508.xml' -> 'Tensorflow/workspace/images/train/please00508.xml'\n",
            "'train/Photo on 13-08-21 at 2.18 AM #3.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.18 AM #3.xml'\n",
            "'train/sorry00502.xml' -> 'Tensorflow/workspace/images/train/sorry00502.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM.xml'\n",
            "'train/sorry00503.xml' -> 'Tensorflow/workspace/images/train/sorry00503.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #2.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #2.xml'\n",
            "'train/sorry00504.xml' -> 'Tensorflow/workspace/images/train/sorry00504.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #6.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #6.xml'\n",
            "'train/please00506.xml' -> 'Tensorflow/workspace/images/train/please00506.xml'\n",
            "'train/Photo on 13-08-21 at 2.18 AM #2.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.18 AM #2.xml'\n",
            "'train/please00510.xml' -> 'Tensorflow/workspace/images/train/please00510.xml'\n",
            "'train/me00509.xml' -> 'Tensorflow/workspace/images/train/me00509.xml'\n",
            "'train/please00504.xml' -> 'Tensorflow/workspace/images/train/please00504.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #8.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #8.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #3.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #3.xml'\n",
            "'train/please00501.xml' -> 'Tensorflow/workspace/images/train/please00501.xml'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #5.xml' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #5.xml'\n",
            "'train/please00502.xml' -> 'Tensorflow/workspace/images/train/please00502.xml'\n",
            "'train/me00510.xml' -> 'Tensorflow/workspace/images/train/me00510.xml'\n",
            "'train/love00501.xml' -> 'Tensorflow/workspace/images/train/love00501.xml'\n",
            "'train/maybe00506.xml' -> 'Tensorflow/workspace/images/train/maybe00506.xml'\n",
            "'train/me00507.xml' -> 'Tensorflow/workspace/images/train/me00507.xml'\n",
            "'train/me00503.xml' -> 'Tensorflow/workspace/images/train/me00503.xml'\n",
            "'train/love00509.xml' -> 'Tensorflow/workspace/images/train/love00509.xml'\n",
            "'train/love00505.xml' -> 'Tensorflow/workspace/images/train/love00505.xml'\n",
            "'train/love00510.xml' -> 'Tensorflow/workspace/images/train/love00510.xml'\n",
            "'train/love00506.xml' -> 'Tensorflow/workspace/images/train/love00506.xml'\n",
            "'train/maybe00510.xml' -> 'Tensorflow/workspace/images/train/maybe00510.xml'\n",
            "'train/me00505.xml' -> 'Tensorflow/workspace/images/train/me00505.xml'\n",
            "'train/maybe00504.xml' -> 'Tensorflow/workspace/images/train/maybe00504.xml'\n",
            "'train/maybe00508.xml' -> 'Tensorflow/workspace/images/train/maybe00508.xml'\n",
            "'train/me00506.xml' -> 'Tensorflow/workspace/images/train/me00506.xml'\n",
            "'train/love00502.xml' -> 'Tensorflow/workspace/images/train/love00502.xml'\n",
            "'train/me00501.xml' -> 'Tensorflow/workspace/images/train/me00501.xml'\n",
            "'train/love00504.xml' -> 'Tensorflow/workspace/images/train/love00504.xml'\n",
            "'train/me00502.xml' -> 'Tensorflow/workspace/images/train/me00502.xml'\n",
            "'train/maybe00503.xml' -> 'Tensorflow/workspace/images/train/maybe00503.xml'\n",
            "'train/maybe00502.xml' -> 'Tensorflow/workspace/images/train/maybe00502.xml'\n",
            "'train/love00503.xml' -> 'Tensorflow/workspace/images/train/love00503.xml'\n",
            "'train/maybe00509.xml' -> 'Tensorflow/workspace/images/train/maybe00509.xml'\n",
            "'train/maybe00501.xml' -> 'Tensorflow/workspace/images/train/maybe00501.xml'\n",
            "'train/me00504.xml' -> 'Tensorflow/workspace/images/train/me00504.xml'\n",
            "'train/love00508.xml' -> 'Tensorflow/workspace/images/train/love00508.xml'\n",
            "'train/maybe00505.xml' -> 'Tensorflow/workspace/images/train/maybe00505.xml'\n",
            "'train/hello00506.xml' -> 'Tensorflow/workspace/images/train/hello00506.xml'\n",
            "'train/help00508.xml' -> 'Tensorflow/workspace/images/train/help00508.xml'\n",
            "'train/how00503.xml' -> 'Tensorflow/workspace/images/train/how00503.xml'\n",
            "'train/help00504.xml' -> 'Tensorflow/workspace/images/train/help00504.xml'\n",
            "'train/how00507.xml' -> 'Tensorflow/workspace/images/train/how00507.xml'\n",
            "'train/help00502.xml' -> 'Tensorflow/workspace/images/train/help00502.xml'\n",
            "'train/help00507.xml' -> 'Tensorflow/workspace/images/train/help00507.xml'\n",
            "'train/how00510.xml' -> 'Tensorflow/workspace/images/train/how00510.xml'\n",
            "'train/how00504.xml' -> 'Tensorflow/workspace/images/train/how00504.xml'\n",
            "'train/help00511.xml' -> 'Tensorflow/workspace/images/train/help00511.xml'\n",
            "'train/how00506.xml' -> 'Tensorflow/workspace/images/train/how00506.xml'\n",
            "'train/help00506.xml' -> 'Tensorflow/workspace/images/train/help00506.xml'\n",
            "'train/hello00507.xml' -> 'Tensorflow/workspace/images/train/hello00507.xml'\n",
            "'train/how00501.xml' -> 'Tensorflow/workspace/images/train/how00501.xml'\n",
            "'train/how00508.xml' -> 'Tensorflow/workspace/images/train/how00508.xml'\n",
            "'train/help00509.xml' -> 'Tensorflow/workspace/images/train/help00509.xml'\n",
            "'train/how00502.xml' -> 'Tensorflow/workspace/images/train/how00502.xml'\n",
            "'train/how00511.xml' -> 'Tensorflow/workspace/images/train/how00511.xml'\n",
            "'train/help00503.xml' -> 'Tensorflow/workspace/images/train/help00503.xml'\n",
            "'train/hello00505.xml' -> 'Tensorflow/workspace/images/train/hello00505.xml'\n",
            "'train/how00509.xml' -> 'Tensorflow/workspace/images/train/how00509.xml'\n",
            "'train/help00501.xml' -> 'Tensorflow/workspace/images/train/help00501.xml'\n",
            "'train/help00505.xml' -> 'Tensorflow/workspace/images/train/help00505.xml'\n",
            "'train/hello00508.xml' -> 'Tensorflow/workspace/images/train/hello00508.xml'\n",
            "'train/help00510.xml' -> 'Tensorflow/workspace/images/train/help00510.xml'\n",
            "'train/girl00502.xml' -> 'Tensorflow/workspace/images/train/girl00502.xml'\n",
            "'train/happy00509.xml' -> 'Tensorflow/workspace/images/train/happy00509.xml'\n",
            "'train/good00503.xml' -> 'Tensorflow/workspace/images/train/good00503.xml'\n",
            "'train/hello00501.xml' -> 'Tensorflow/workspace/images/train/hello00501.xml'\n",
            "'train/good00504.xml' -> 'Tensorflow/workspace/images/train/good00504.xml'\n",
            "'train/happy00506.xml' -> 'Tensorflow/workspace/images/train/happy00506.xml'\n",
            "'train/happy00505.xml' -> 'Tensorflow/workspace/images/train/happy00505.xml'\n",
            "'train/good00506.xml' -> 'Tensorflow/workspace/images/train/good00506.xml'\n",
            "'train/hello00502.xml' -> 'Tensorflow/workspace/images/train/hello00502.xml'\n",
            "'train/good00508.xml' -> 'Tensorflow/workspace/images/train/good00508.xml'\n",
            "'train/girl00504.xml' -> 'Tensorflow/workspace/images/train/girl00504.xml'\n",
            "'train/happy00507.xml' -> 'Tensorflow/workspace/images/train/happy00507.xml'\n",
            "'train/happy00501.xml' -> 'Tensorflow/workspace/images/train/happy00501.xml'\n",
            "'train/girl00505.xml' -> 'Tensorflow/workspace/images/train/girl00505.xml'\n",
            "'train/girl00503.xml' -> 'Tensorflow/workspace/images/train/girl00503.xml'\n",
            "'train/hello00503.xml' -> 'Tensorflow/workspace/images/train/hello00503.xml'\n",
            "'train/good00501.xml' -> 'Tensorflow/workspace/images/train/good00501.xml'\n",
            "'train/good00502.xml' -> 'Tensorflow/workspace/images/train/good00502.xml'\n",
            "'train/happy00503.xml' -> 'Tensorflow/workspace/images/train/happy00503.xml'\n",
            "'train/girl00506.xml' -> 'Tensorflow/workspace/images/train/girl00506.xml'\n",
            "'train/happy00510.xml' -> 'Tensorflow/workspace/images/train/happy00510.xml'\n",
            "'train/happy00504.xml' -> 'Tensorflow/workspace/images/train/happy00504.xml'\n",
            "'train/happy00502.xml' -> 'Tensorflow/workspace/images/train/happy00502.xml'\n",
            "'train/good00507.xml' -> 'Tensorflow/workspace/images/train/good00507.xml'\n",
            "'train/girl00507.xml' -> 'Tensorflow/workspace/images/train/girl00507.xml'\n",
            "'train/family00505.xml' -> 'Tensorflow/workspace/images/train/family00505.xml'\n",
            "'train/bad00502.xml' -> 'Tensorflow/workspace/images/train/bad00502.xml'\n",
            "'train/family00501.xml' -> 'Tensorflow/workspace/images/train/family00501.xml'\n",
            "'train/boy00503.xml' -> 'Tensorflow/workspace/images/train/boy00503.xml'\n",
            "'train/baby00512.xml' -> 'Tensorflow/workspace/images/train/baby00512.xml'\n",
            "'train/family00503.xml' -> 'Tensorflow/workspace/images/train/family00503.xml'\n",
            "'train/baby00511.xml' -> 'Tensorflow/workspace/images/train/baby00511.xml'\n",
            "'train/boy00501.xml' -> 'Tensorflow/workspace/images/train/boy00501.xml'\n",
            "'train/boy00507.xml' -> 'Tensorflow/workspace/images/train/boy00507.xml'\n",
            "'train/bad00504.xml' -> 'Tensorflow/workspace/images/train/bad00504.xml'\n",
            "'train/bad00505.xml' -> 'Tensorflow/workspace/images/train/bad00505.xml'\n",
            "'train/bad00506.xml' -> 'Tensorflow/workspace/images/train/bad00506.xml'\n",
            "'train/boy00502.xml' -> 'Tensorflow/workspace/images/train/boy00502.xml'\n",
            "'train/boy00505.xml' -> 'Tensorflow/workspace/images/train/boy00505.xml'\n",
            "'train/baby00510.xml' -> 'Tensorflow/workspace/images/train/baby00510.xml'\n",
            "'train/boy00508.xml' -> 'Tensorflow/workspace/images/train/boy00508.xml'\n",
            "'train/family00504.xml' -> 'Tensorflow/workspace/images/train/family00504.xml'\n",
            "'train/family00502.xml' -> 'Tensorflow/workspace/images/train/family00502.xml'\n",
            "'train/family00506.xml' -> 'Tensorflow/workspace/images/train/family00506.xml'\n",
            "'train/boy00506.xml' -> 'Tensorflow/workspace/images/train/boy00506.xml'\n",
            "'train/baby00513.xml' -> 'Tensorflow/workspace/images/train/baby00513.xml'\n",
            "'train/baby00514.xml' -> 'Tensorflow/workspace/images/train/baby00514.xml'\n",
            "'train/family00507.xml' -> 'Tensorflow/workspace/images/train/family00507.xml'\n",
            "'train/bad00501.xml' -> 'Tensorflow/workspace/images/train/bad00501.xml'\n",
            "'train/bad00503.xml' -> 'Tensorflow/workspace/images/train/bad00503.xml'\n",
            "'train/yes00510.jpg' -> 'Tensorflow/workspace/images/train/yes00510.jpg'\n",
            "'train/you00509.jpg' -> 'Tensorflow/workspace/images/train/you00509.jpg'\n",
            "'train/yes00512.jpg' -> 'Tensorflow/workspace/images/train/yes00512.jpg'\n",
            "'train/you00506.jpg' -> 'Tensorflow/workspace/images/train/you00506.jpg'\n",
            "'train/baby00504.xml' -> 'Tensorflow/workspace/images/train/baby00504.xml'\n",
            "'train/you00501.jpg' -> 'Tensorflow/workspace/images/train/you00501.jpg'\n",
            "'train/yes00509.jpg' -> 'Tensorflow/workspace/images/train/yes00509.jpg'\n",
            "'train/yes00508.jpg' -> 'Tensorflow/workspace/images/train/yes00508.jpg'\n",
            "'train/.DS_Store' -> 'Tensorflow/workspace/images/train/.DS_Store'\n",
            "'train/you00503.jpg' -> 'Tensorflow/workspace/images/train/you00503.jpg'\n",
            "'train/you00508.jpg' -> 'Tensorflow/workspace/images/train/you00508.jpg'\n",
            "'train/baby00508.xml' -> 'Tensorflow/workspace/images/train/baby00508.xml'\n",
            "'train/baby00506.xml' -> 'Tensorflow/workspace/images/train/baby00506.xml'\n",
            "'train/baby00509.xml' -> 'Tensorflow/workspace/images/train/baby00509.xml'\n",
            "'train/yes00513.jpg' -> 'Tensorflow/workspace/images/train/yes00513.jpg'\n",
            "'train/you00502.jpg' -> 'Tensorflow/workspace/images/train/you00502.jpg'\n",
            "'train/baby00502.xml' -> 'Tensorflow/workspace/images/train/baby00502.xml'\n",
            "'train/yes00506.jpg' -> 'Tensorflow/workspace/images/train/yes00506.jpg'\n",
            "'train/baby00505.xml' -> 'Tensorflow/workspace/images/train/baby00505.xml'\n",
            "'train/baby00503.xml' -> 'Tensorflow/workspace/images/train/baby00503.xml'\n",
            "'train/baby00507.xml' -> 'Tensorflow/workspace/images/train/baby00507.xml'\n",
            "'train/you00505.jpg' -> 'Tensorflow/workspace/images/train/you00505.jpg'\n",
            "'train/you00504.jpg' -> 'Tensorflow/workspace/images/train/you00504.jpg'\n",
            "'train/you00511.jpg' -> 'Tensorflow/workspace/images/train/you00511.jpg'\n",
            "'train/yes00511.jpg' -> 'Tensorflow/workspace/images/train/yes00511.jpg'\n",
            "'train/which00506.jpg' -> 'Tensorflow/workspace/images/train/which00506.jpg'\n",
            "'train/who00503.jpg' -> 'Tensorflow/workspace/images/train/who00503.jpg'\n",
            "'train/which00508.jpg' -> 'Tensorflow/workspace/images/train/which00508.jpg'\n",
            "'train/which00503.jpg' -> 'Tensorflow/workspace/images/train/which00503.jpg'\n",
            "'train/which00512.jpg' -> 'Tensorflow/workspace/images/train/which00512.jpg'\n",
            "'train/yes00502.jpg' -> 'Tensorflow/workspace/images/train/yes00502.jpg'\n",
            "'train/who00507.jpg' -> 'Tensorflow/workspace/images/train/who00507.jpg'\n",
            "'train/yes00505.jpg' -> 'Tensorflow/workspace/images/train/yes00505.jpg'\n",
            "'train/which00504.jpg' -> 'Tensorflow/workspace/images/train/which00504.jpg'\n",
            "'train/which00502.jpg' -> 'Tensorflow/workspace/images/train/which00502.jpg'\n",
            "'train/which00505.jpg' -> 'Tensorflow/workspace/images/train/which00505.jpg'\n",
            "'train/yes00504.jpg' -> 'Tensorflow/workspace/images/train/yes00504.jpg'\n",
            "'train/which00509.jpg' -> 'Tensorflow/workspace/images/train/which00509.jpg'\n",
            "'train/who00504.jpg' -> 'Tensorflow/workspace/images/train/who00504.jpg'\n",
            "'train/yes00501.jpg' -> 'Tensorflow/workspace/images/train/yes00501.jpg'\n",
            "'train/which00511.jpg' -> 'Tensorflow/workspace/images/train/which00511.jpg'\n",
            "'train/who00501.jpg' -> 'Tensorflow/workspace/images/train/who00501.jpg'\n",
            "'train/who00502.jpg' -> 'Tensorflow/workspace/images/train/who00502.jpg'\n",
            "'train/who00509.jpg' -> 'Tensorflow/workspace/images/train/who00509.jpg'\n",
            "'train/who00505.jpg' -> 'Tensorflow/workspace/images/train/who00505.jpg'\n",
            "'train/who00510.jpg' -> 'Tensorflow/workspace/images/train/who00510.jpg'\n",
            "'train/yes00503.jpg' -> 'Tensorflow/workspace/images/train/yes00503.jpg'\n",
            "'train/which00510.jpg' -> 'Tensorflow/workspace/images/train/which00510.jpg'\n",
            "'train/which00507.jpg' -> 'Tensorflow/workspace/images/train/which00507.jpg'\n",
            "'train/who00508.jpg' -> 'Tensorflow/workspace/images/train/who00508.jpg'\n",
            "'train/what00506.jpg' -> 'Tensorflow/workspace/images/train/what00506.jpg'\n",
            "'train/where00505.jpg' -> 'Tensorflow/workspace/images/train/where00505.jpg'\n",
            "'train/welcome00515.jpg' -> 'Tensorflow/workspace/images/train/welcome00515.jpg'\n",
            "'train/welcome00510.jpg' -> 'Tensorflow/workspace/images/train/welcome00510.jpg'\n",
            "'train/where00506.jpg' -> 'Tensorflow/workspace/images/train/where00506.jpg'\n",
            "'train/where00508.jpg' -> 'Tensorflow/workspace/images/train/where00508.jpg'\n",
            "'train/what00503.jpg' -> 'Tensorflow/workspace/images/train/what00503.jpg'\n",
            "'train/what00508.jpg' -> 'Tensorflow/workspace/images/train/what00508.jpg'\n",
            "'train/welcome00514.jpg' -> 'Tensorflow/workspace/images/train/welcome00514.jpg'\n",
            "'train/what00505.jpg' -> 'Tensorflow/workspace/images/train/what00505.jpg'\n",
            "'train/welcome00518.jpg' -> 'Tensorflow/workspace/images/train/welcome00518.jpg'\n",
            "'train/what00502.jpg' -> 'Tensorflow/workspace/images/train/what00502.jpg'\n",
            "'train/where00502.jpg' -> 'Tensorflow/workspace/images/train/where00502.jpg'\n",
            "'train/where00511.jpg' -> 'Tensorflow/workspace/images/train/where00511.jpg'\n",
            "'train/where00507.jpg' -> 'Tensorflow/workspace/images/train/where00507.jpg'\n",
            "'train/what00507.jpg' -> 'Tensorflow/workspace/images/train/what00507.jpg'\n",
            "'train/where00504.jpg' -> 'Tensorflow/workspace/images/train/where00504.jpg'\n",
            "'train/where00509.jpg' -> 'Tensorflow/workspace/images/train/where00509.jpg'\n",
            "'train/what00509.jpg' -> 'Tensorflow/workspace/images/train/what00509.jpg'\n",
            "'train/what00501.jpg' -> 'Tensorflow/workspace/images/train/what00501.jpg'\n",
            "'train/where00510.jpg' -> 'Tensorflow/workspace/images/train/where00510.jpg'\n",
            "'train/welcome00516.jpg' -> 'Tensorflow/workspace/images/train/welcome00516.jpg'\n",
            "'train/welcome00517.jpg' -> 'Tensorflow/workspace/images/train/welcome00517.jpg'\n",
            "'train/where00503.jpg' -> 'Tensorflow/workspace/images/train/where00503.jpg'\n",
            "'train/what00510.jpg' -> 'Tensorflow/workspace/images/train/what00510.jpg'\n",
            "'train/sorry00511.jpg' -> 'Tensorflow/workspace/images/train/sorry00511.jpg'\n",
            "'train/sorry00506.jpg' -> 'Tensorflow/workspace/images/train/sorry00506.jpg'\n",
            "'train/welcome00511.jpg' -> 'Tensorflow/workspace/images/train/welcome00511.jpg'\n",
            "'train/please00510.jpg' -> 'Tensorflow/workspace/images/train/please00510.jpg'\n",
            "'train/sorry00503.jpg' -> 'Tensorflow/workspace/images/train/sorry00503.jpg'\n",
            "'train/sorry00501.jpg' -> 'Tensorflow/workspace/images/train/sorry00501.jpg'\n",
            "'train/sorry00508.jpg' -> 'Tensorflow/workspace/images/train/sorry00508.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #7.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #7.jpg'\n",
            "'train/Photo on 13-08-21 at 2.18 AM #2.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.18 AM #2.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #2.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #2.jpg'\n",
            "'train/sorry00507.jpg' -> 'Tensorflow/workspace/images/train/sorry00507.jpg'\n",
            "'train/please00508.jpg' -> 'Tensorflow/workspace/images/train/please00508.jpg'\n",
            "'train/sorry00502.jpg' -> 'Tensorflow/workspace/images/train/sorry00502.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #4.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #4.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #5.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #5.jpg'\n",
            "'train/Photo on 13-08-21 at 2.18 AM #3.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.18 AM #3.jpg'\n",
            "'train/welcome00513.jpg' -> 'Tensorflow/workspace/images/train/welcome00513.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM.jpg'\n",
            "'train/welcome00512.jpg' -> 'Tensorflow/workspace/images/train/welcome00512.jpg'\n",
            "'train/sorry00505.jpg' -> 'Tensorflow/workspace/images/train/sorry00505.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #6.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #6.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #8.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #8.jpg'\n",
            "'train/sorry00504.jpg' -> 'Tensorflow/workspace/images/train/sorry00504.jpg'\n",
            "'train/sorry00509.jpg' -> 'Tensorflow/workspace/images/train/sorry00509.jpg'\n",
            "'train/Photo on 13-08-21 at 2.17 AM #3.jpg' -> 'Tensorflow/workspace/images/train/Photo on 13-08-21 at 2.17 AM #3.jpg'\n",
            "'train/me00505.jpg' -> 'Tensorflow/workspace/images/train/me00505.jpg'\n",
            "'train/me00503.jpg' -> 'Tensorflow/workspace/images/train/me00503.jpg'\n",
            "'train/maybe00505.jpg' -> 'Tensorflow/workspace/images/train/maybe00505.jpg'\n",
            "'train/please00506.jpg' -> 'Tensorflow/workspace/images/train/please00506.jpg'\n",
            "'train/maybe00504.jpg' -> 'Tensorflow/workspace/images/train/maybe00504.jpg'\n",
            "'train/maybe00502.jpg' -> 'Tensorflow/workspace/images/train/maybe00502.jpg'\n",
            "'train/me00501.jpg' -> 'Tensorflow/workspace/images/train/me00501.jpg'\n",
            "'train/me00502.jpg' -> 'Tensorflow/workspace/images/train/me00502.jpg'\n",
            "'train/please00501.jpg' -> 'Tensorflow/workspace/images/train/please00501.jpg'\n",
            "'train/maybe00509.jpg' -> 'Tensorflow/workspace/images/train/maybe00509.jpg'\n",
            "'train/me00509.jpg' -> 'Tensorflow/workspace/images/train/me00509.jpg'\n",
            "'train/maybe00506.jpg' -> 'Tensorflow/workspace/images/train/maybe00506.jpg'\n",
            "'train/please00507.jpg' -> 'Tensorflow/workspace/images/train/please00507.jpg'\n",
            "'train/maybe00503.jpg' -> 'Tensorflow/workspace/images/train/maybe00503.jpg'\n",
            "'train/please00503.jpg' -> 'Tensorflow/workspace/images/train/please00503.jpg'\n",
            "'train/please00502.jpg' -> 'Tensorflow/workspace/images/train/please00502.jpg'\n",
            "'train/maybe00508.jpg' -> 'Tensorflow/workspace/images/train/maybe00508.jpg'\n",
            "'train/please00505.jpg' -> 'Tensorflow/workspace/images/train/please00505.jpg'\n",
            "'train/me00507.jpg' -> 'Tensorflow/workspace/images/train/me00507.jpg'\n",
            "'train/me00510.jpg' -> 'Tensorflow/workspace/images/train/me00510.jpg'\n",
            "'train/please00504.jpg' -> 'Tensorflow/workspace/images/train/please00504.jpg'\n",
            "'train/me00504.jpg' -> 'Tensorflow/workspace/images/train/me00504.jpg'\n",
            "'train/maybe00510.jpg' -> 'Tensorflow/workspace/images/train/maybe00510.jpg'\n",
            "'train/me00506.jpg' -> 'Tensorflow/workspace/images/train/me00506.jpg'\n",
            "'train/maybe00501.jpg' -> 'Tensorflow/workspace/images/train/maybe00501.jpg'\n",
            "'train/how00504.jpg' -> 'Tensorflow/workspace/images/train/how00504.jpg'\n",
            "'train/love00504.jpg' -> 'Tensorflow/workspace/images/train/love00504.jpg'\n",
            "'train/love00501.jpg' -> 'Tensorflow/workspace/images/train/love00501.jpg'\n",
            "'train/how00503.jpg' -> 'Tensorflow/workspace/images/train/how00503.jpg'\n",
            "'train/help00510.jpg' -> 'Tensorflow/workspace/images/train/help00510.jpg'\n",
            "'train/help00511.jpg' -> 'Tensorflow/workspace/images/train/help00511.jpg'\n",
            "'train/how00510.jpg' -> 'Tensorflow/workspace/images/train/how00510.jpg'\n",
            "'train/how00502.jpg' -> 'Tensorflow/workspace/images/train/how00502.jpg'\n",
            "'train/love00502.jpg' -> 'Tensorflow/workspace/images/train/love00502.jpg'\n",
            "'train/love00508.jpg' -> 'Tensorflow/workspace/images/train/love00508.jpg'\n",
            "'train/how00511.jpg' -> 'Tensorflow/workspace/images/train/how00511.jpg'\n",
            "'train/help00508.jpg' -> 'Tensorflow/workspace/images/train/help00508.jpg'\n",
            "'train/love00509.jpg' -> 'Tensorflow/workspace/images/train/love00509.jpg'\n",
            "'train/how00506.jpg' -> 'Tensorflow/workspace/images/train/how00506.jpg'\n",
            "'train/help00507.jpg' -> 'Tensorflow/workspace/images/train/help00507.jpg'\n",
            "'train/help00506.jpg' -> 'Tensorflow/workspace/images/train/help00506.jpg'\n",
            "'train/love00505.jpg' -> 'Tensorflow/workspace/images/train/love00505.jpg'\n",
            "'train/how00501.jpg' -> 'Tensorflow/workspace/images/train/how00501.jpg'\n",
            "'train/love00503.jpg' -> 'Tensorflow/workspace/images/train/love00503.jpg'\n",
            "'train/how00509.jpg' -> 'Tensorflow/workspace/images/train/how00509.jpg'\n",
            "'train/love00510.jpg' -> 'Tensorflow/workspace/images/train/love00510.jpg'\n",
            "'train/help00509.jpg' -> 'Tensorflow/workspace/images/train/help00509.jpg'\n",
            "'train/how00507.jpg' -> 'Tensorflow/workspace/images/train/how00507.jpg'\n",
            "'train/love00506.jpg' -> 'Tensorflow/workspace/images/train/love00506.jpg'\n",
            "'train/how00508.jpg' -> 'Tensorflow/workspace/images/train/how00508.jpg'\n",
            "'train/hello00506.jpg' -> 'Tensorflow/workspace/images/train/hello00506.jpg'\n",
            "'train/hello00505.jpg' -> 'Tensorflow/workspace/images/train/hello00505.jpg'\n",
            "'train/happy00503.jpg' -> 'Tensorflow/workspace/images/train/happy00503.jpg'\n",
            "'train/hello00502.jpg' -> 'Tensorflow/workspace/images/train/hello00502.jpg'\n",
            "'train/happy00501.jpg' -> 'Tensorflow/workspace/images/train/happy00501.jpg'\n",
            "'train/hello00507.jpg' -> 'Tensorflow/workspace/images/train/hello00507.jpg'\n",
            "'train/help00503.jpg' -> 'Tensorflow/workspace/images/train/help00503.jpg'\n",
            "'train/happy00506.jpg' -> 'Tensorflow/workspace/images/train/happy00506.jpg'\n",
            "'train/happy00507.jpg' -> 'Tensorflow/workspace/images/train/happy00507.jpg'\n",
            "'train/help00501.jpg' -> 'Tensorflow/workspace/images/train/help00501.jpg'\n",
            "'train/happy00510.jpg' -> 'Tensorflow/workspace/images/train/happy00510.jpg'\n",
            "'train/good00506.jpg' -> 'Tensorflow/workspace/images/train/good00506.jpg'\n",
            "'train/happy00502.jpg' -> 'Tensorflow/workspace/images/train/happy00502.jpg'\n",
            "'train/hello00503.jpg' -> 'Tensorflow/workspace/images/train/hello00503.jpg'\n",
            "'train/help00502.jpg' -> 'Tensorflow/workspace/images/train/help00502.jpg'\n",
            "'train/happy00505.jpg' -> 'Tensorflow/workspace/images/train/happy00505.jpg'\n",
            "'train/happy00504.jpg' -> 'Tensorflow/workspace/images/train/happy00504.jpg'\n",
            "'train/good00504.jpg' -> 'Tensorflow/workspace/images/train/good00504.jpg'\n",
            "'train/hello00508.jpg' -> 'Tensorflow/workspace/images/train/hello00508.jpg'\n",
            "'train/good00508.jpg' -> 'Tensorflow/workspace/images/train/good00508.jpg'\n",
            "'train/happy00509.jpg' -> 'Tensorflow/workspace/images/train/happy00509.jpg'\n",
            "'train/help00505.jpg' -> 'Tensorflow/workspace/images/train/help00505.jpg'\n",
            "'train/help00504.jpg' -> 'Tensorflow/workspace/images/train/help00504.jpg'\n",
            "'train/good00507.jpg' -> 'Tensorflow/workspace/images/train/good00507.jpg'\n",
            "'train/hello00501.jpg' -> 'Tensorflow/workspace/images/train/hello00501.jpg'\n",
            "'train/family00504.jpg' -> 'Tensorflow/workspace/images/train/family00504.jpg'\n",
            "'train/girl00507.jpg' -> 'Tensorflow/workspace/images/train/girl00507.jpg'\n",
            "'train/boy00505.jpg' -> 'Tensorflow/workspace/images/train/boy00505.jpg'\n",
            "'train/family00501.jpg' -> 'Tensorflow/workspace/images/train/family00501.jpg'\n",
            "'train/girl00505.jpg' -> 'Tensorflow/workspace/images/train/girl00505.jpg'\n",
            "'train/boy00503.jpg' -> 'Tensorflow/workspace/images/train/boy00503.jpg'\n",
            "'train/boy00502.jpg' -> 'Tensorflow/workspace/images/train/boy00502.jpg'\n",
            "'train/family00502.jpg' -> 'Tensorflow/workspace/images/train/family00502.jpg'\n",
            "'train/family00507.jpg' -> 'Tensorflow/workspace/images/train/family00507.jpg'\n",
            "'train/good00501.jpg' -> 'Tensorflow/workspace/images/train/good00501.jpg'\n",
            "'train/family00506.jpg' -> 'Tensorflow/workspace/images/train/family00506.jpg'\n",
            "'train/good00503.jpg' -> 'Tensorflow/workspace/images/train/good00503.jpg'\n",
            "'train/boy00508.jpg' -> 'Tensorflow/workspace/images/train/boy00508.jpg'\n",
            "'train/girl00503.jpg' -> 'Tensorflow/workspace/images/train/girl00503.jpg'\n",
            "'train/family00503.jpg' -> 'Tensorflow/workspace/images/train/family00503.jpg'\n",
            "'train/bad00506.jpg' -> 'Tensorflow/workspace/images/train/bad00506.jpg'\n",
            "'train/boy00507.jpg' -> 'Tensorflow/workspace/images/train/boy00507.jpg'\n",
            "'train/boy00501.jpg' -> 'Tensorflow/workspace/images/train/boy00501.jpg'\n",
            "'train/good00502.jpg' -> 'Tensorflow/workspace/images/train/good00502.jpg'\n",
            "'train/boy00506.jpg' -> 'Tensorflow/workspace/images/train/boy00506.jpg'\n",
            "'train/girl00502.jpg' -> 'Tensorflow/workspace/images/train/girl00502.jpg'\n",
            "'train/bad00505.jpg' -> 'Tensorflow/workspace/images/train/bad00505.jpg'\n",
            "'train/girl00504.jpg' -> 'Tensorflow/workspace/images/train/girl00504.jpg'\n",
            "'train/family00505.jpg' -> 'Tensorflow/workspace/images/train/family00505.jpg'\n",
            "'train/girl00506.jpg' -> 'Tensorflow/workspace/images/train/girl00506.jpg'\n",
            "'train/baby00503.jpg' -> 'Tensorflow/workspace/images/train/baby00503.jpg'\n",
            "'train/baby00502.jpg' -> 'Tensorflow/workspace/images/train/baby00502.jpg'\n",
            "'train/baby00512.jpg' -> 'Tensorflow/workspace/images/train/baby00512.jpg'\n",
            "'train/bad00504.jpg' -> 'Tensorflow/workspace/images/train/bad00504.jpg'\n",
            "'train/baby00509.jpg' -> 'Tensorflow/workspace/images/train/baby00509.jpg'\n",
            "'train/baby00514.jpg' -> 'Tensorflow/workspace/images/train/baby00514.jpg'\n",
            "'train/baby00511.jpg' -> 'Tensorflow/workspace/images/train/baby00511.jpg'\n",
            "'train/bad00502.jpg' -> 'Tensorflow/workspace/images/train/bad00502.jpg'\n",
            "'train/bad00503.jpg' -> 'Tensorflow/workspace/images/train/bad00503.jpg'\n",
            "'train/baby00505.jpg' -> 'Tensorflow/workspace/images/train/baby00505.jpg'\n",
            "'train/baby00507.jpg' -> 'Tensorflow/workspace/images/train/baby00507.jpg'\n",
            "'train/baby00506.jpg' -> 'Tensorflow/workspace/images/train/baby00506.jpg'\n",
            "'train/baby00504.jpg' -> 'Tensorflow/workspace/images/train/baby00504.jpg'\n",
            "'train/baby00510.jpg' -> 'Tensorflow/workspace/images/train/baby00510.jpg'\n",
            "'train/bad00501.jpg' -> 'Tensorflow/workspace/images/train/bad00501.jpg'\n",
            "'train/baby00508.jpg' -> 'Tensorflow/workspace/images/train/baby00508.jpg'\n",
            "'train/baby00513.jpg' -> 'Tensorflow/workspace/images/train/baby00513.jpg'\n",
            "'test' -> 'Tensorflow/workspace/images/test'\n",
            "'test/me00508.jpg' -> 'Tensorflow/workspace/images/test/me00508.jpg'\n",
            "'test/girl00501.jpg' -> 'Tensorflow/workspace/images/test/girl00501.jpg'\n",
            "'test/please00509.jpg' -> 'Tensorflow/workspace/images/test/please00509.jpg'\n",
            "'test/hello00504.jpg' -> 'Tensorflow/workspace/images/test/hello00504.jpg'\n",
            "'test/happy00508.jpg' -> 'Tensorflow/workspace/images/test/happy00508.jpg'\n",
            "'test/Photo on 13-08-21 at 2.18 AM.jpg' -> 'Tensorflow/workspace/images/test/Photo on 13-08-21 at 2.18 AM.jpg'\n",
            "'test/you00510.jpg' -> 'Tensorflow/workspace/images/test/you00510.jpg'\n",
            "'test/how00505.jpg' -> 'Tensorflow/workspace/images/test/how00505.jpg'\n",
            "'test/what00504.jpg' -> 'Tensorflow/workspace/images/test/what00504.jpg'\n",
            "'test/love00507.jpg' -> 'Tensorflow/workspace/images/test/love00507.jpg'\n",
            "'test/boy00504.jpg' -> 'Tensorflow/workspace/images/test/boy00504.jpg'\n",
            "'test/who00506.jpg' -> 'Tensorflow/workspace/images/test/who00506.jpg'\n",
            "'test/welcome00519.jpg' -> 'Tensorflow/workspace/images/test/welcome00519.jpg'\n",
            "'test/good00505.jpg' -> 'Tensorflow/workspace/images/test/good00505.jpg'\n",
            "'test/where00501.jpg' -> 'Tensorflow/workspace/images/test/where00501.jpg'\n",
            "'test/you00507.jpg' -> 'Tensorflow/workspace/images/test/you00507.jpg'\n",
            "'test/sorry00510.jpg' -> 'Tensorflow/workspace/images/test/sorry00510.jpg'\n",
            "'test/baby00501.jpg' -> 'Tensorflow/workspace/images/test/baby00501.jpg'\n",
            "'test/.DS_Store' -> 'Tensorflow/workspace/images/test/.DS_Store'\n",
            "'test/which00501.jpg' -> 'Tensorflow/workspace/images/test/which00501.jpg'\n",
            "'test/help00512.jpg' -> 'Tensorflow/workspace/images/test/help00512.jpg'\n",
            "'test/maybe00507.jpg' -> 'Tensorflow/workspace/images/test/maybe00507.jpg'\n",
            "'test/yes00507.jpg' -> 'Tensorflow/workspace/images/test/yes00507.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "7JZtCPRR8QSF",
        "outputId": "9e49e65a-5c47-4ae4-dc20-f827fca5a398"
      },
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "    --use-deprecated=legacy-resolver\n",
        "# if os.name=='nt':\n",
        "#     url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "#     wget.download(url)\n",
        "#     !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "#     !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "#     os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "#     !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "#     !cd Tensorflow/models/research/slim && pip install -e ."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-9ec0c0778947>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    --use-deprecated=legacy-resolver\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't assign to operator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGN4b5DU9MHd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b92dc0f-e0e5-4727-88ff-fa09748fc44d"
      },
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py\", line 25, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "ModuleNotFoundError: No module named 'object_detection'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyglHCDX9mv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8de7bb-2674-4875-d32a-2818f3524ff6"
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.39.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.34.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lweP_KSo91vy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "bbdce5e5-04ee-4260-c656-23d350422c29"
      },
      "source": [
        "import object_detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1a19769998a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeghIeao-bsi"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "# if os.name == 'nt':\n",
        "#     wget.download(PRETRAINED_MODEL_URL)\n",
        "#     !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "#     !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeHH3LWE-fmK"
      },
      "source": [
        "#train=!unzip /content/drive/MyDrive/projectfiles/duplicates/train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYbtQYHK-lsu"
      },
      "source": [
        "#test = !unzip /content/drive/MyDrive/projectfiles/duplicates/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRt1Wo3AAIxK"
      },
      "source": [
        "**Label map**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA-yUe5m-tQE"
      },
      "source": [
        "labels = [{'name':'baby', 'id':1}, {'name':'bad', 'id':2}, {'name':'boy', 'id':3}, {'name':'family', 'id':4},\n",
        "          {'name':'girl', 'id':5}, {'name':'good', 'id':6}, {'name':'happy', 'id':7}, {'name':'hello', 'id':8},\n",
        "          {'name':'help', 'id':9}, {'name':'how', 'id':10}, {'name':'love', 'id':11}, {'name':'maybe', 'id':12},\n",
        "          {'name':'me', 'id':13}, {'name':'please', 'id':14}, {'name':'sad', 'id':15}, {'name':'sorry', 'id':15},\n",
        "          {'name':'welcome', 'id':16}, {'name':'what', 'id':17}, {'name':'where', 'id':18}, {'name':'which', 'id':19},\n",
        "          {'name':'who', 'id':20}, {'name':'why', 'id':21}, {'name':'yes', 'id':22}, {'name':'you', 'id':23}]\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOUPt33KAXFb"
      },
      "source": [
        "creating TF records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS9x7euuAEIz"
      },
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDtCrGwzAaeS"
      },
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyPBUTRSAt5w"
      },
      "source": [
        "#####FOR TRAINING###\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNsotwJMAcS6"
      },
      "source": [
        "#Dont run it for training,this is for training\n",
        "#!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}\n",
        "#!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLgpXZY8AiAF"
      },
      "source": [
        " Copying Model Configuration to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQUJhTxTAeZP"
      },
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "# if os.name == 'nt':\n",
        "#     !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcEHDH8eArSm"
      },
      "source": [
        "The transfer learning bit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAIi1A3aApRk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDczfverAvgQ"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L025tMAUAxHo"
      },
      "source": [
        "config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7U91hMAy0z"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grmLeNb1A1f3"
      },
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XC2P4QPMtdX"
      },
      "source": [
        "print(pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJtGkt3KA3e3"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzdW0cdCA7Xb"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ai8NZfkA5nF"
      },
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4uMPysRBAVt"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLAsEiFyBCEh"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waGsmdDDBDhB"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sZnKIzCBJ1l"
      },
      "source": [
        "Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxeszkhDPLCo"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSlQdvqrBFlI"
      },
      "source": [
        "#command = \"python {} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv8TgijIBPAm"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f3ZPF5JORVe"
      },
      "source": [
        "#python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYdFd2pgBSmU"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfjepnGoBadx"
      },
      "source": [
        "Loading Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSKCYJwvBc46"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9_p1firKgtH"
      },
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PctNlF9wKoa-"
      },
      "source": [
        "Detecting from image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElMKbS0jKjyl"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssMHXprnKq7b"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2fhalZlKr_H"
      },
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'test', 'you-00006.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRQKD8jKKvm7"
      },
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J42zT18QK0ln"
      },
      "source": [
        "#!pip uninstall opencv-python-headless -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3VgjDtK7hd"
      },
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwNvdaWLJuM"
      },
      "source": [
        "Freezing graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAe9I2-hLD3r"
      },
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLi1pGEHLHnQ"
      },
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifuMfRlTLLO5"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-enWZ_4LM8U"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aDT2674LSme"
      },
      "source": [
        "Conversion to TFLite\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlCgiERfLOl-"
      },
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJh-lD4wLVjJ"
      },
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdVhU-oxLcr2"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYMAsUMyLfIV"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59-tAOJB5fgk"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zytp56H5jBT"
      },
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMCoTPgk5vnj"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrZggO4a5xe7"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sPdGdi2Lo0R"
      },
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLV18CBHLxi1"
      },
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61cEHzgqL1qu"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pjEM6_sL3U7"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_9cdZs2L8i0"
      },
      "source": [
        "ZIPPING FOR EXPORT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_J-LDMQL5RO"
      },
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOa4BwUhL7Hr"
      },
      "source": []
    }
  ]
}